# NCRS Project Overview

**Last Updated**: 2025-11-10
**System Version**: 2.0.0 - Vision Architecture
**Status**: Production-ready, fully operational

---

## System Summary

NCRS (Neuromorphic Commonsense Reasoning System) is a hybrid neuromorphic-LLM reasoning system that combines spiking neural networks (SNNs) with large language models to perform commonsense reasoning over ConceptNet knowledge graphs.

### Key Statistics

- **Total Files**: 2,057 files
  - Core NCRS: ~262 Python files
  - API layer: ~50 files
  - Tests: ~144 files
  - Frontend: ~80 TypeScript files
  - Other: ~1,521 files (generated, migrations, utilities)
- **Workflow Steps**: 8 complete stages
- **LLM Calls per Query**: 7-8 calls (1 classification + 5 HyDe + 1-2 seed + 1 synthesis)
- **Average Query Time**: ~1,835ms (1.8 seconds)
- **Knowledge Base**: ConceptNet 5.5 (1.8M concepts, 3.4M edges)
- **Test Coverage**: ~67% overall (144 test files)
- **Configuration Files**: 13-17 YAML files across 3 directories

### Performance Metrics

- **Total Query Latency**: ~1,835ms average
- **Primary Bottleneck**: Multi-Path SNN (1,234ms = 66.8% of total time)
- **LLM Latency**: Classification (52ms), HyDe (243ms), Synthesis (201ms)
- **Failure Rate**: < 5%
- **JSON Generation Success**: > 95% first attempt (Outlines), > 99.5% with retry
- **Convergence Rate**: ‚â• 50% target

### Memory Usage

- **SNN (9-column sparse)**: ~2.1GB RAM baseline, ~2.8GB peak
- **LLM (via RPC)**: 3.6GB VRAM (shared, runs on RPC server)
- **Embedding Cache**: ~1.66GB on disk, ~500MB in RAM
- **Total**: ~2.1-2.8GB RAM + 3.6GB VRAM

---

## Architecture Layers

### 6-Layer System Architecture

```
Layer 6: Frontend (React + TypeScript)
  - 8 visualization components (65KB)
  - SSE event streaming
  - Zustand state management

Layer 5: API (FastAPI)
  - NCRSAdapter (async/sync bridge)
  - EventBus (real-time events)
  - SSE streaming (1,027 lines)

Layer 4: Facade (Orchestration)
  - facade_workflow.py (554 lines)
  - 8-step workflow coordination
  - Performance tracking

Layer 3: Workflow Steps
  - 8 pipeline stages (262 files)
  - Classification, HyDe, Seed, SNN, Synthesis

Layer 2: Core Services
  - LLMClient, StateManager, PerformanceTracker
  - Hop runner, Path manager, Orchestrator

Layer 1: Foundation
  - EmbeddingCache, RPCClient, Utils
  - Brian2 SNN, ConceptNet CSV
```

---

## 8-Step Workflow

| Step | Component | Status | LLM Calls | Latency |
|------|-----------|--------|-----------|---------|
| 1 | Query Classification | ‚úÖ Complete | 1 | 52ms |
| 2 | HyDe Goal Generation | ‚úÖ Complete | 5 | 243ms |
| 3 | Seed Extraction | ‚úÖ Complete | 1-2 | 98ms |
| 4 | Goal Region Creation | ‚úÖ Complete | 0 | 1ms |
| 5 | Multi-Path SNN Exploration | ‚úÖ Complete | 0 | 1,234ms |
| 6 | Regression Detection | ‚úÖ Complete | 0 | 1ms |
| 7 | Path Persistence | ‚úÖ Complete | 0 | 5ms |
| 8 | Answer Synthesis | ‚úÖ Complete | 1 | 201ms |

**Total**: 7-8 LLM calls per query, ~1,835ms average latency

---

## Critical Dependencies

### Cannot Function Without
1. **Brian2** (>=2.5.0) - SNN simulation (NO fallback)
2. **NumPy** (>=1.24.0) - Embeddings & arrays (NO fallback)
3. **Pandas** (>=2.0.0) - ConceptNet CSV lookup (NO fallback)
4. **ConceptNet Embeddings** (1.66GB) - Required on disk (NO fallback)
5. **Qwen RPC Server** (localhost:9090) - LLM inference (HyDe has fallback)

### Deprecated Dependencies (Should Remove)
- `sentence-transformers>=2.2.0` ‚ùå Unused (LLM-based embeddings now)
- `torch>=2.5.0` ‚ùå Unused (backend for sentence-transformers)
- `transformers>=4.50.0` ‚ùå Unused (LLM via RPC)
- `spacy>=3.5.0` ‚ùå Deprecated NER

---

## System Strengths

1. ‚úÖ **Complete Implementation**: All 8 workflow steps fully functional
2. ‚úÖ **Comprehensive Testing**: 144 test files (~67% coverage)
3. ‚úÖ **Real-Time Visualization**: SSE event streaming to frontend
4. ‚úÖ **Graceful Degradation**: HyDe has 3-tier fallback chain
5. ‚úÖ **Modular Architecture**: NO circular dependencies
6. ‚úÖ **Performance Monitoring**: Dedicated bottleneck tracking
7. ‚úÖ **Path Recording**: Full JSONL persistence for debugging
8. ‚úÖ **Dual Seed Strategies**: Query decomposition + variants in parallel

---

## Known Issues & Gaps

### üî¥ Critical Gaps (P0)
1. **Parallel Path Execution** - Missing concurrency tests
2. **k-WTA Edge Cases** - Missing edge case tests for core selection

### üü° High Priority Gaps (P1)
1. **CSV Fuzzy Search Edge Cases** - Missing edge case handling
2. **Embedding Cache Eviction** - Missing cache management tests
3. **Network Validation** - Insufficient SNN validation tests
4. **RPC Timeout Handling** - Missing timeout scenario tests

### üü¢ Medium Priority Gaps (P2)
1. **Async HyDe Implementation** - Optional, not used by default
2. **Facade Edge Cases** - Missing error scenario tests
3. **Performance Stress Tests** - Missing 1000+ query stress tests

---

## Primary Entry Points

### Python API
```python
from ncrs import NCRS

system = NCRS(data_source='data/')
result = system.run_query(
    query="What causes traffic accidents?",
    max_seeds=50,
    max_workers=8
)
```

### REST API
```bash
POST http://localhost:8000/api/v1/query
{
  "query": "What causes traffic accidents?",
  "max_seeds": 50,
  "max_workers": 8
}
```

### SSE Event Streaming
```bash
GET http://localhost:8000/api/v1/events?query_id=abc123
```

---

## Key Performance Bottlenecks

1. üî¥ **Multi-Path SNN** (1,234ms = 66.8%) - Brian2 simulation overhead
2. üî¥ **HyDe Ensemble** (243ms = 13.2%) - 5 sequential LLM calls
3. ‚ö†Ô∏è **Answer Synthesis** (201ms = 10.9%) - Single LLM call
4. ‚ö†Ô∏è **Seed Extraction** (98ms = 5.3%) - LLM + fuzzy search

### Optimization Potential
- **HyDe**: Switch to async parallel calls (already implemented, not default)
- **SNN**: Increase max_workers from 8 to 16 (CPU dependent)
- **Caching**: Cache query classifications and decompositions

---

## Deployment Requirements

### Compute Resources
- **CPU**: 4+ cores recommended (for 8 parallel workers)
- **RAM**: 4GB minimum (8GB recommended)
- **GPU**: Not required (Qwen RPC runs on separate server)
- **Disk**: 2GB+ for embeddings and cache

### External Services
- **Qwen RPC Server**: localhost:9090 (BF16 precision, 3.6GB VRAM)
- **ConceptNet Data**: CSV files in `data/` directory
- **Embedding Cache**: 1.66GB NPZ file in `data/`

---

## Development Status

**Overall Implementation**: ‚úÖ 100% complete (all 8 workflow steps functional)

**Test Coverage**: ‚ö†Ô∏è 67% (target: 85%+)
- Facade: 40-65%
- Workflow: 60-80%
- Core Operations: 60-85%
- Infrastructure: 45-75%
- SNN Architecture: 30-65%

**Documentation**: ‚úÖ Excellent
- WORKFLOW.md: 93% accurate (needs minor updates)
- API documentation: Present
- Configuration: Well-documented

---

## Next Steps (Recommendations)

### High Priority
1. Remove unused dependencies (sentence-transformers, torch, transformers, spacy)
2. Add startup health checks (Brian2, ConceptNet, Qwen RPC)
3. Document Qwen RPC setup guide
4. Add LLM fallbacks for classification and synthesis

### Medium Priority
5. Increase test coverage to 80%+
6. Switch to async HyDe as default
7. Add embedding compression or lazy loading
8. Monitor LLM costs and latency

### Low Priority
9. Consolidate source directories (`/ncrs` and `/src/ncrs`)
10. Archive temporary query directories

---

**Last Verified**: 2025-11-10
**Phase 0 Analysis**: Complete ‚úÖ
**System Health**: EXCELLENT
